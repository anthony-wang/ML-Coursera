using CSV, Plots; pyplot();

data = CSV.read("/Users/kevinliu/Documents/machine-learning-ex2/ex2/ex2data1.txt", datarow=1)

X = hcat(ones(100,1), Matrix(data[:, [1,2]]))
y = Vector(data[:, 3])

function sigmoid(z)
    1.0 ./ (1.0 .+ exp.(-z))
end

function h(θ, X)
    z = 0
    for i in 1:length(θ)
        z += θ[i] .* X[i, :]
    end
    sigmoid(z)
end

h([0,0], X)

function cost(θ, X, y)
    m = length(y) # number of training examples
    errorsum = 0
    for i in 1:m
        if y[i] == 1
            error = y[i] * log.(h(θ, X[i, :]))
        else y[i] == 0
            error = (1 - y[i]) * log.(1 - h(θ, X[i, :]))
        end
        errorsum += error
    end
    const constant = - 1 / m
    global J = constant * errorsum
    println("Cost is $J")
end

cost([0,0], X, y)

function cost_deriv(X, y, θ, j, α)
    m = length(y)
    errorsum = 0
    for i = 1:m, j = 1:size(X, 2)
        error = (h(θ, X[i, :]) - y[i]) .* X[i, j]
        errorsum += error
    end
    const constant = float(α) / float(m)
    J = constant * errorsum
end

cost_deriv(X, y, [0,0], 2, 0.1)

function gd(X, y, θ, α)
    m = length(y)
    θ_new = []
    const constant = α / m
    for j in 1:length(θ)
        θ_new_value = θ[j] - cost_deriv(X, y, θ, j, α)
        append!(θ_new, θ_new_value)
    end
    θ_new
end

gd(X, y, [0,0], 0.1)

function logit(X, y, θ, α, iter)
    for i in 1:iter
        θ_new = gd(X, y, θ, α)
        θ = θ_new
        if mod.(i, 100) == 0
            # cost returns final hypothesis of model
            cost(θ, X, y)
        end
    end
    println("θ is $θ")
    println("J is $(cost(θ, X, y))")
end

logit(X, y, [0, 0], 0.1, 1000)
